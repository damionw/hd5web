#! /usr/bin/env bash

http::hdf5::url_mappings() {
    url::add_handler '^\/$' GET http::hdf5::response_index
    url::add_handler '^\/index.html$' GET http::hdf5::response_index
    url::add_handler '^\/api\/files[\/]*$' GET http::hdf5::get_filelist
    url::add_handler '^\/api\/tree[\/]*$' GET http::hdf5::get_tree
    url::add_handler '^\/api\/content[\/].*$' GET http::hdf5::get_content
    url::add_handler '^\/static\/.*$' GET http::response_file
}

http::hdf5::importlib() {
    . "$("${__HD5WEB_BINARY__}" --lib)"
}

http::hdf5::response_index() {
    http::response_file GET index.html "${3}"
}

http::hdf5::get_filelist() {
    http::hdf5::importlib

    hdf5::files | {
        echo "{"
        echo "\"files\": ["
        awk '{printf("%s\"%s\"\n", sep, $0); sep=",";}'
        echo "]"
        echo "}"
    } | http::response_json
}

http::hdf5::get_tree() {
    local _descriptor=
    local _fs1=

    http::hdf5::importlib

    {
        echo "{"
        echo "\"nodes\": ["

        hdf5::files | hdf5::map hdf5::dir | while read _descriptor
        do
            eval "${_descriptor}"

            local _pathnodes="$(
                echo "root${path}" | awk -F/ '{
                    for (i=1; i <= NF; ++i) {
                        if (length($i) > 0) {
                            print $i;
                        }
                    }
                }'
            )"

            local _parent="$(
                echo "${_pathnodes}" |
                head --lines=-1 |
                awk '{printf("%s%s", sep, (NR > 1 ? $0 : "/")); if (NR > 1) {sep="/";}}'
            )"

            local _name=$(
                echo "${_pathnodes}" |
                tail -1
            )

            echo "${_fs1}{"
            echo "\"filename\": \"${filename}\""
            echo ",\"path\": \"${path}\""
            echo ",\"name\": \"${_name}\""
            echo ",\"parent\": \"${_parent}\""
            echo ",\"type\": \"${type}\""
            echo "}"

            _fs1=","
        done

        echo "]"
        echo "}"
    } | http::response_json
}

http::hdf5::get_content() {
    local _method="${1}" _request="${2}" _headers="${3}" _content="${4}"

    http::hdf5::importlib

    local _truncated="$(echo "${_request}" | sed -e 's/^.*\/content\/*//1')"
    local _parameters="$(echo "${_request}" | sed -e 's/^.*[\?]//1')"
    local _filename="$(echo "${_truncated}" | awk -F/ '{print $1;}')"
    local _node="$(echo "${_truncated}" | sed -e 's/^[^\/]*[\/]*//1')"
    local _name
    local _value
    local _header
    local _row
    local _sep

    echo "${_parameters}" | awk -F\& '{for (i=1; i <= NF; ++i) {print $i;}}' | sed -e 's/=/ /1' | {
        while read _name _value
        do
            local _value="$(echo "${_value}" | sed -e's/%\([0-9A-F][0-9A-F]\)/\\\\\x\1/g' | xargs echo -e)"
            logging::warning "${_name}=\"${_value}\""
            eval "${_name}=\"${_value}\""
        done

        hdf5::content "${filename}" "${path}" "${offset:-0}" "${count}" | {
            read _header

            echo "{"
            echo "\"columns\": [${_header}]"
            echo ",\"data\": ["

            _sep=

            while read _row
            do
                echo "${_sep}[${_row}]"
                _sep=","
            done

            echo "]"
            echo "}"
        }
    } | http::response_json
}